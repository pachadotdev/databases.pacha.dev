---
title: "SQL Databases for Students and Educators"
author: "Pach√°"
date: "2022-12-12"
output:
  rmdformats::downcute:    
    self_contained: false
    default_style: dark
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

*Update 2022-12-12: I'm using just PostgreSQL. I just had too many heaches
with MariaDB/MySQL. Also, the server is quite modest and I prefer to provide 
good PostgreSQL access than bad access to PostgreSQL and MariaDB.*

*Update 2022-09-30: The SQL Server educational license expired. From now on,
only PostgreSQL and MariaDB databases will be available.*

# About

Publicly accessible databases often impose query limits or require registration. 
Even when I maintain public and limit-free APIs, I never wanted to host a public 
database because I tend to think that the connection strings are a problem for 
the user.

I've decided to host different light/medium size by using PostgreSQL. I tend to 
prefer PostgreSQL because it easier to configure on client and server side, 
without strange tricks (see the *Problems with MySQL/MariaDB and SQL Server* 
section).

If I can secure funding for this, I will make the same databases available under
different backends (even MariaDB **and** MySQL at the same time). There are a 
ton of small edge cases when moving between DB back ends and so testing lots with
live databases is quite valuable. With this resource you can benchmark speed, 
compression, and DDL types.

If you need access to the online DBs (i.e., not configuring your local copy) or
you need technical support, send me an email to 
m.sepulveda+spam@mail.utoronto.ca (replace with +databases for a faster reply).

You can contribute to keep it up with the hosting costs here:

<script type="text/javascript" src="https://cdnjs.buymeacoffee.com/1.0.0/button.prod.min.js" data-name="bmc-button" data-slug="pacha" data-color="#FFDD00" data-emoji=""  data-font="Cookie" data-text="Buy me a coffee" data-outline-color="#000000" data-font-color="#000000" data-coffee-color="#ffffff" ></script>

# Available Databases

## Open Trade Statistics

This is the database that powers [Open Trade Statistics](https://shiny.tradestatistics.io/countryprofiles) and
contains international trade data for commodities since 2002.

This database can be helpful for evaluating the impact of free trade agreements,
and other policy relevant modelling. The database is a modified version of the
United Nations Commodity Trade Statistics Database (UN COMTRADE) and is targeted
for Latin American Universities, who often have limited or no access to the
original resource.

Access these tables by adapting the next code:

```{r, message=FALSE}
library(dplyr)
library(RPostgres)

con <- dbConnect(
  Postgres(),
  user = Sys.getenv("dbedu_usr"),
  password = Sys.getenv("dbedu_pwd"),
  dbname = "tradestatistics",
  host = "databases.pacha.dev"
)

dbListTables(con)

tbl(con, "yrpc") %>% glimpse()

dbDisconnect(con)
```

## Base Hansard

A complete PostgreSQL database of the Canadian Hansard dataset, including 
supplementary data. It covers the Canadian Hansard from 1901 to 2019 and
was obtained from [LiPaD](https://www.lipad.ca/) with the intention of
providing a live SQL database for users interested in this data. The
original site provides a SQL dump that requires you to configure PostreSQL
on your own laptop or server.

```{r, message=FALSE}
library(dplyr)
library(RPostgres)

con <- dbConnect(
  Postgres(),
  user = Sys.getenv("dbedu_usr"),
  password = Sys.getenv("dbedu_pwd"),
  dbname = "basehansard",
  host = "databases.pacha.dev"
)

dbListTables(con)

tbl(con, "dilipadsite_basehansard") %>% glimpse()

dbDisconnect(con)
```

## Intendo

It's a dummy database that originally we used at the [My Organization's First R Package](https://github.com/rstudio-conf-2020/my-org-first-pkg) and contains 
managerial information of a company called Intendo, which creates mobile games. 
The tables contain information for the 2015 year for all sorts of information 
for their only game: Super Jetroid. See the recent updated to this
database at [intendo](https://github.com/rich-iannone/intendo).

This database can be helpful for workshops and showing how to create an R 
package focused on the particular needs of an organization, including easier 
data access, shared functions for data transformation and analysis, and a common
look and feel for reporting.

Check the structure of the tables in the next preview. The tables ending with
"_f" contain deliberated errors.

```{r, message=FALSE}
library(dplyr)
library(RPostgres)

con <- dbConnect(
  Postgres(),
  user = Sys.getenv("dbedu_usr"),
  password = Sys.getenv("dbedu_pwd"),
  dbname = "intendo",
  host = "databases.pacha.dev"
)

dbListTables(con)

tbl(con, "sj_user_summary_small") %>% glimpse()

dbDisconnect(con)
```

## Financial (aka Loan Application)

A database that contains Financial dataset contains 606 successful and 76 not 
successful loans along with their information and transactions.

This database comes from the [Relational Dataset Repository](https://relational.fit.cvut.cz/dataset/Financial) where you can find
the database schema and more information. The database full name is "PKDD'99 
Financial Dataset or Loan Application", and this particular version corresponds 
to Financial_ijs by Janez Kranjc.

Access these tables by adapting the next code:

```{r, message=FALSE}
library(dplyr)
library(RPostgres)

con <- dbConnect(
  Postgres(),
  user = Sys.getenv("dbedu_usr"),
  password = Sys.getenv("dbedu_pwd"),
  dbname = "financial",
  host = "databases.pacha.dev"
)

dbListTables(con)

tbl(con, "clients") %>% glimpse()
```

<!-- ## CENSO 2017 -->

<!-- Backends -->

<!-- - [x] PostgreSQL -->
<!-- - [ ] MariaDB -->

<!-- This database combines two source, [censo2017 R package](https://github.com/ropensci/censo2017) (uses DuckDB as locla backend) -->
<!-- and [censo2017 cartographies](https://github.com/ropensci/censo2017-cartografias). -->

<!-- Please read the documentation in the mentioned sources. Because of GIS structure -->
<!-- in some tables, I'm bounded to use PostgreSQL with PostGIS. -->

# SQL dumps

<!-- 
sudo -i -u postgres
pg_dump -Fc intendo > intendo-postgres.sql
md5sum intendo.sql > intendo.sql.md5
-->

All the dumps are available for PostgreSQL to promote its use. I had just too 
many problems with MariaDB/MySQL configuration and even more with SQL Server
(see the *Problems with MySQL/Maria and SQL Server* section).

## Open Trade Statistics

* [PostgreSQL](https://databases.pacha.dev/dumps/tradestatistics-postgres.sql) (1.8 GB, check the download with the [md5sum](https://databases.pacha.dev/dumps/tradestatistics-postgres.sql.md5))

## Intendo

* [PostgreSQL](https://databases.pacha.dev/dumps/intendo-postgres.sql) (554 MB, check the download with the [md5sum](https://databases.pacha.dev/dumps/intendo-postgres.sql.md5))

## Financial

* [PostgreSQL](https://databases.pacha.dev/dumps/financial-postgres.sql) (13 MB, check the download with the [md5sum](https://databases.pacha.dev/dumps/financial-postgres.sql.md5))

<!-- ## CENSO2017 -->

<!-- * [PostgreSQL](https://databases.pacha.dev/dumps/censo2017.sql) (850 MB, check the download with the [md5sum](https://databases.pacha.dev/dumps/censo2017.sql.md5)) -->

# Using the dumps locally

## Restore dumps

### PostgreSQL

```bash
sudo -i -u postgres
pg_restore intendo.sql -d intendo
```

<!-- ### MySQL/MariaDB -->

<!-- <!-- mysqldump intendo > intendo-mysql.sql -->

<!-- From SQL: -->

<!-- ``` SQL -->
<!-- # mysql  -->
<!-- CREATE DATABASE intendo; -->
<!-- ``` -->

<!-- Then from bash: -->
<!-- ```bash -->
<!-- sudo su -->
<!-- gunzip intendo-mysql.sql -->
<!-- mysql intendo < intendo-mysql.sql -->
<!-- ``` -->

<!-- ### SQL Server -->

<!-- <!-- BACKUP DATABASE intendo TO DISK = 'filepath';  -->

<!-- From bash: -->
<!-- ```bash -->
<!-- gunzip intendo-mysql.sql -->
<!-- sqlcmd -S localhost -U SA -->
<!-- ``` -->

<!-- Then in SQL: -->
<!-- ```SQL -->
<!-- RESTORE DATABASE intendo FROM DISK = 'intendo-sqlserver.sql' -->
<!-- GO -->
<!-- ``` -->

## Create users

You can create a generic user (let's say `student`) and grant read-only access.

### PostgreSQL

```SQL
# sudo -i -u postgres 
# psql -d intendo
CREATE ROLE student;
CREATE ROLE teacher;
ALTER ROLE student WITH ENCRYPTED PASSWORD 'SomePassword';
ALTER ROLE teacher WITH ENCRYPTED PASSWORD 'SomePassword';
ALTER ROLE student WITH LOGIN;
ALTER ROLE teacher WITH LOGIN;

GRANT CONNECT ON DATABASE intendo TO student;
GRANT USAGE ON SCHEMA public TO student;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO student;
GRANT SELECT ON ALL SEQUENCES IN SCHEMA public TO student;
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO student;
REVOKE CREATE ON SCHEMA public FROM public;

GRANT CONNECT ON DATABASE intendo TO teacher;
GRANT USAGE ON SCHEMA public TO teacher;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO teacher;
GRANT SELECT ON ALL SEQUENCES IN SCHEMA public TO teacher;
ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT SELECT ON TABLES TO teacher;
GRANT CREATE ON SCHEMA public TO teacher;
```

<!-- ### MySQL/MariaDB -->

<!-- ```SQL -->
<!-- # sudo mysql -->
<!-- USE intendo; -->

<!-- CREATE USER student IDENTIFIED BY 'SomePassword'; -->
<!-- CREATE USER teacher IDENTIFIED BY 'SomePassword'; -->

<!-- GRANT SELECT ON intendo.* TO student; -->

<!-- GRANT SELECT ON intendo.* TO teacher; -->
<!-- GRANT CREATE ON intendo.* TO teacher; -->
<!-- GRANT INSERT ON intendo.* TO teacher; -->
<!-- GRANT ALTER ON intendo.* TO teacher; -->
<!-- ``` -->

<!-- ### SQL Server -->

<!-- ```SQL -->
<!-- # sqlcmd -S localhost -U SA -->

<!-- USE intendo -->
<!-- GO -->

<!-- CREATE LOGIN student WITH PASSWORD = 'SomePassword' -->
<!-- GO -->
<!-- CREATE USER student FOR LOGIN student -->
<!-- GO -->
<!-- GRANT SELECT ON SCHEMA :: dbo TO student -->
<!-- GO -->

<!-- CREATE LOGIN teacher WITH PASSWORD = 'SomePassword' -->
<!-- GO -->
<!-- CREATE USER teacher FOR LOGIN teacher -->
<!-- GO -->
<!-- GRANT SELECT ON SCHEMA :: dbo TO teacher -->
<!-- GO -->
<!-- GRANT CREATE TABLE TO teacher -->
<!-- GO -->
<!-- GRANT INSERT ON SCHEMA :: dbo TO teacher -->
<!-- GO -->
<!-- GRANT ALTER ON SCHEMA :: dbo TO teacher -->
<!-- GO -->
<!-- GRANT UPDATE ON SCHEMA :: dbo TO teacher -->
<!-- GO -->

<!-- # You'll also want to limit SQL Server memory -->
<!-- # This avoids strange crashes -->
<!-- sp_configure 'show advanced options', 1; -->
<!-- GO -->
<!-- RECONFIGURE; -->
<!-- GO -->
<!-- sp_configure 'max server memory', 1024; -->
<!-- GO -->
<!-- RECONFIGURE; -->
<!-- GO -->
<!-- ``` -->

## Allow external connections

For this project I had to allow connections from outside the server.

### Postgres (version 14)

1. Open `/etc/postgresql/14/main/postgresql.conf`, comment the line that says `listen_addresses = 'localhost'`,
add `listen_address = '*'` below it.
2. Open `/etc/postgresql/14/main/pg_hba.conf`, paste these lines at the end
```bash
host    all             all     0.0.0.0/0       md5
host    all             all     :/0             md5
```
3. Run `sudo systemctl restart postgresql`.
4. Open the port with `sudo ufw allow 5432/tcp`.

<!-- ### MariaDB (i.e. MySQL replacement) -->

<!-- 1. Open `/etc/mysql/mariadb.conf.d/50-server.cnf`, comment the line that says `bind-address = 127.0.0.1`. -->
<!-- 2. Run `sudo systemctl restart mysql`. -->
<!-- 3. Open the port with `sudo ufw allow 3306/tcp`. -->

<!-- ### SQL Server -->

<!-- 3. Access as administrator and run -->
<!-- ```SQL -->
<!-- EXEC sys.sp_configure N'remote access', N'1' -->
<!-- GO -->
<!-- RECONFIGURE WITH OVERRIDE -->
<!-- GO -->
<!-- ``` -->
<!-- 2. Open the ports with  -->
<!-- ```bash -->
<!-- sudo ufw allow 1433/tcp -->
<!-- sudo ufw allow 4022/tcp -->
<!-- sudo ufw allow 135/tcp -->
<!-- sudo ufw allow 1434/tcp -->
<!-- sudo ufw allow 1434/udp -->
<!-- ``` -->

## Changing database location

### PostgreSQL

Create a new dir, stop the service and copy the PostgreSQL data directory to the new location.

```bash
sudo mkdir /postgres
sudo chown -R postgres:postgres /postgres
sudo systemctl stop postgresql
sudo rsync -av /var/lib/postgresql/ /postgres
sudo nano /etc/postgresql/14/main/postgresql.conf
```

Then search `data_directory` and change the location to `/postgresql/14/main`. 

Finally start the service again.

<!-- ###  MySQL/MariaDB -->

<!-- Create a new dir, stop the service and copy the MariaDB data directory to the new location. -->

<!-- ```bash -->
<!-- sudo mkdir /mysql -->
<!-- sudo chown -R mysql:mysql /mysql -->
<!-- sudo systemctl stop mariadb -->
<!-- sudo cp -R -p /var/lib/mysql/* /mysql/ -->
<!-- sudo nano /etc/mysql/mariadb.conf.d/50-server.cnf -->
<!-- ``` -->

<!-- Then search `datadir` to `/mariadb`.  -->

<!-- Finally start the service again. -->

<!-- ```bash -->
<!-- sudo systemctl start mariadb -->
<!-- ``` -->

<!-- With my MySQL is slightly different. -->

# Problems with MySQL/Maria and SQL Server

## MySQL/MariaDB

From R, the RMariaDB package copies around 20 times slower than RMySQL. Using 
odbc for this SQL backend is not very efficient. Just use RMySQL.

When you backup, at least with MariaDB, `mysqldump intendo > intendo-mysql.sql` 
is hundreds of times faster than `mysql intendo > intendo-mysql.sql`.

## SQL Server

Beware that SQL Server shows strange problems with Linux and Mac! For example, 
when I connect from a Mac, I experience random disconnections and the next error
message:
```bash
nanodbc/nanodbc.cpp:4483: 00000: [Microsoft][ODBC Driver 18 for SQL Server]Communication link failure 
```
With Ubuntu I get this another error message and RStudio crashes:
```bash
terminate called after throwing an instance of 'nanodbc::database_error'
```
I had to divide my data and write in chunks of 50,000 rows or it just 
disconnects. PostgreSQL and MariaDB can write tables containing two million rows
right away.

Therefore, my preference for DB backends is not arbitrary.

# Cite this work

This work is licensed under [Creative Commons  Attribution 4.0 International (CC BY 4.0) ](https://creativecommons.org/licenses/by/4.0/).

BibTeX entry:
```
@misc{databases_pacha,
  title = {SQL Databases for Students and Educators},
  url = {https://databases.pacha.dev/},
  author = {Vargas, Mauricio},
  doi = {10.5281/zenodo.4136985},
  publisher = {Self-published},
  year = {2021},
  month = {Feb},
  note = {Accessed: Month DD, YYYY}
}
```
